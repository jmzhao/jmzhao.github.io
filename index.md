# Jinman Zhao

I am an applied scientist at Amazon Web Services. My team focuses on large foundation models.
Before that, I was [a PhD student](http://pages.cs.wisc.edu/~jz/) at University of Wisconsin-Madison.
Before that, I was an undergrad at Nanjing University.

My research interest lies broadly in the intersection of machine learning, programming language and natural language. 
Some specific topics include machine learning for code (ML4Code), language models, efficiency, and interpretability.

---
### Papers
(\* indicates equal contribution) <br/>
- **Large Language Models of Code Fail at Completing Code with Potential Bugs**, <br/>
Tuan Dinh\*, _Jinman Zhao_\*, Samson Tan, Renato Negrinho, Leonard Lausen, Sheng Zha, George Karypis. <br/>
[arXiv](https://arxiv.org/abs/2306.03438)
- **Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion**, <br/>
Hengzhi Pei, _Jinman Zhao_, Leonard Lausen, Sheng Zha, George Karypis. <br/>
Accepted to AAAI 2023 / [arXiv](https://arxiv.org/abs/2306.00381)
- **Code Prediction by Feeding Trees to Transformers**, <br/>
Seohyun Kim\*, _Jinman Zhao_\*, Yuchi Tian, Satish Chandra. <br/>
[ICSE 2021](https://conf.researchr.org/details/icse-2021/icse-2021-papers/132/Code-Prediction-by-Feeding-Trees-to-Transformers)
/ [arXiv](https://arxiv.org/abs/2003.13848)
- <a id="pbos"></a>**PBoS: Probabilistic Bag-of-Subwords for Generalizing Word Embedding**, <br/>
_Zhao Jinman_, Shawn Zhong, Xiaomin Zhang, Yingyu Liang. <br/>
[Findings of EMNLP 2020](https://www.aclweb.org/anthology/2020.findings-emnlp.53/)
/ [arXiv](https://arxiv.org/abs/2010.10813)
/ [slides](https://docs.google.com/presentation/d/1Ut5goTIali363GLZ48Se-ot14OaDcc2fthwPIT9dHe8/)
/ [talk](https://slideslive.com/38940115/)
- <a id="embedding-subwords"></a>**Generalizing Word Embeddings using Bag of Subwords**, <br/>
_Jinman Zhao_, Sidharth Mudgal, Yingyu Liang. <br/>
[EMNLP 2018](http://aclweb.org/anthology/D18-1059)
/ [arXiv](https://arxiv.org/abs/1809.04259)
/ [slides](static/docs/emnlp-2018-generalizing-slides.pdf)
/ [talk](https://vimeo.com/305197257)
- <a id="neural-android"></a>**Neural-Augmented Static Analysis of Android Communication**, <br/>
_Jinman Zhao_, Aws Albarghouthi, Vaibhav Rastogi, Somesh Jha, Damien Octeau. <br/>
[FSE 2018](https://dl.acm.org/citation.cfm?id=3236066)
/ [arXiv](https://arxiv.org/abs/1809.04059)
/ [slides](static/docs/fse-2018-neural-augmented-slides.pdf)
/ [poster](static/docs/neural-augmented-poster-mwpls.pdf)
- <a id="nn-width"></a>**The Effect of Network Width on the Performance of Large-batch Training**, <br/>
Lingjiao Chen, Hongyi Wang, _Jinman Zhao_, Dimitris Papailiopoulos, Paraschos Koutris. <br/>
[NeurIPS 2018](https://papers.nips.cc/paper/8142-the-effect-of-network-width-on-the-performance-of-large-batch-training)
/ [arXiv](https://arxiv.org/abs/1806.03791)


### Selected Reports
- <a id="invest-embedding"/>**Investigating the skip-gram word embedding model**, 2017 Spring.
- <a id="low-facial"/>**Low resolution facial landmark detection**, 2016 Spring. 
- <a id="comment-topics"/>**Learning comment topics from code**, 2016 Spring.


### Service & Activities
- Mentored Tuan Dinh, Hengzhi Pei, Samika Gupta, Shawn Zhong.
- Reviewer of 
  - NeurIPS’23, AMLC'23, Amazon Research Award '23, ICML’23, AISTATS’23, ICLR’23, AAAI’23;
  - NeurIPS’22, AMLC'22, Amazon Research Award '22, ICML’22 (highlighted reviewer), AISTATS’22 (top reviewer), ICLR’22, AAAI’22; 
  - NeurIPS’21, AAAI’21; 
  - EMNLP'20, NeurIPS’20, AAAI'20; 
  - NeurIPS'19, ICML'19. 
- Subreviewer of SysML'20, WWW'20.
- Coach of the [UW-Madison's ICPC Team](http://pages.cs.wisc.edu/~dieter/ICPC/18-19/) '17-'19.
- Chair of the [UW-Madison's SACM](http://sacm.cs.wisc.edu/) Event Committee '18-'19.

---
Previous PhD site: http://pages.cs.wisc.edu/~jz/


<div style="color:lightgray">
  <sub><sup>Last updated 2023/06.</sup></sub>
</div>
